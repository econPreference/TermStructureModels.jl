<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Estimation · TermStructureModels.jl</title><meta name="title" content="Estimation · TermStructureModels.jl"/><meta property="og:title" content="Estimation · TermStructureModels.jl"/><meta property="twitter:title" content="Estimation · TermStructureModels.jl"/><meta name="description" content="Documentation for TermStructureModels.jl."/><meta property="og:description" content="Documentation for TermStructureModels.jl."/><meta property="twitter:description" content="Documentation for TermStructureModels.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">TermStructureModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../notations/">Notations</a></li><li class="is-active"><a class="tocitem" href>Estimation</a><ul class="internal"><li><a class="tocitem" href="#Step-1.-Tuning-Hyperparameters"><span>Step 1. Tuning Hyperparameters</span></a></li><li><a class="tocitem" href="#Step-2.-Sampling-the-Posterior-Distribution-of-Parameters"><span>Step 2. Sampling the Posterior Distribution of Parameters</span></a></li><li><a class="tocitem" href="#Step-3.-Discard-Burn-in-and-Nonstationary-Posterior-Samples"><span>Step 3. Discard Burn-in and Nonstationary Posterior Samples</span></a></li><li><a class="tocitem" href="#Diagnostics-for-MCMC"><span>Diagnostics for MCMC</span></a></li></ul></li><li><a class="tocitem" href="../inference/">Statistical Inference</a></li><li><a class="tocitem" href="../scenario/">Forecasting</a></li><li><a class="tocitem" href="../output/">Utilization of the Output</a></li><li><a class="tocitem" href="../others/">Other Forms of the Model</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/econPreference/TermStructureModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/econPreference/TermStructureModels.jl/blob/main/docs/src/estimation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Estimation"><a class="docs-heading-anchor" href="#Estimation">Estimation</a><a id="Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation" title="Permalink"></a></h1><p>To estimate the model, the following two steps must be undertaken.</p><h2 id="Step-1.-Tuning-Hyperparameters"><a class="docs-heading-anchor" href="#Step-1.-Tuning-Hyperparameters">Step 1. Tuning Hyperparameters</a><a id="Step-1.-Tuning-Hyperparameters-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1.-Tuning-Hyperparameters" title="Permalink"></a></h2><p>We have five hyperparameters, <code>p</code>, <code>q</code>, <code>nu0</code>, <code>Omega0</code>, and <code>mean_phi_const</code>.</p><ul><li><code>p::Float64</code>: lag length of the <span>$\mathbb{P}$</span>-VAR(p)</li><li><code>q::Matrix{Float64}( , 4, 2)</code>: Shrinkage degrees in the Minnesota prior</li><li><code>nu0::Float64</code>(d.f.) and <code>Omega0::Vector</code>(diagonals of the scale matrix): Prior distribution of the error covariance matrix in the <span>$\mathbb{P}$</span>-VAR(p)</li><li><code>mean_phi_const</code>: Prior mean of the intercept term in the <span>$\mathbb{P}$</span>-VAR(p)</li></ul><p>We recommend <a href="../api/#TermStructureModels.tuning_hyperparameter-NTuple{4, Any}"><code>tuning_hyperparameter</code></a> for deciding the hyperparameters.</p><pre><code class="language-julia hljs">tuned, results = tuning_hyperparameter(yields, macros, tau_n, rho;
                                        populationsize=50,
                                        maxiter=10_000,
                                        medium_tau=collect(24:3:48),
                                        upper_q=[1 1; 1 1; 10 10; 100 100],
                                        mean_kQ_infty=0,
                                        std_kQ_infty=0.1,
                                        upper_nu0=[],
                                        mean_phi_const=[],
                                        fix_const_PC1=false,
                                        upper_p=18,
                                        mean_phi_const_PC1=[],
                                        data_scale=1200,
                                        kappaQ_prior_pr=[],
                                        init_nu0=[],
                                        is_pure_EH=false,
                                        psi_common=[],
                                        psi_const=[])</code></pre><p>Note that the default upper bound of <code>p</code> is <code>upper_p=18</code>. The output <code>tuned::Hyperparameter</code> is the object that needs to be obtained in Step 1. <code>results</code> contains the optimization results.</p><p>If users accept our default values, the function is simplified, that is</p><pre><code class="language-julia hljs">tuned, results = tuning_hyperparameter(yields, macros, tau_n, rho)</code></pre><p><code>yields</code> is a <code>T</code> by <code>N</code> matrix, and <code>T</code> is the length of the sample period. <code>N</code> is the number of maturities in data. <code>tau_n</code> is a <code>N</code>-Vector that contains bond maturities in data. For example, if there are two maturities, 3 and 24 months, in the monthly term structure model, <code>tau_n=[3; 24]</code>. <code>macros</code> is a <code>T</code> by <code>dP-dQ</code> matrix in which each column is an individual macroeconomic variable. <code>rho</code> is a <code>dP-dQ</code>-Vector. In general, <code>rho[i] = 1</code> if <code>macros[:, i]</code> is in level, or it is set to 0 if the macro variable is differenced.</p><h3 id="Several-relevant-points-regarding-hyperparameter-optimization"><a class="docs-heading-anchor" href="#Several-relevant-points-regarding-hyperparameter-optimization">Several relevant points regarding hyperparameter optimization</a><a id="Several-relevant-points-regarding-hyperparameter-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Several-relevant-points-regarding-hyperparameter-optimization" title="Permalink"></a></h3><h4 id="Computational-Cost-of-the-Optimization"><a class="docs-heading-anchor" href="#Computational-Cost-of-the-Optimization">Computational Cost of the Optimization</a><a id="Computational-Cost-of-the-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Cost-of-the-Optimization" title="Permalink"></a></h4><p>Since we adopt the Differential Evolutionary(DE) algorithm (Specifically, <a href="https://github.com/robertfeldt/BlackBoxOptim.jl"><code>BlackBoxOptim.jl</code></a>), it is hard to set the terminal condition. Our strategy was to run the algorithm with a sufficient number of iterations (our default settings) and to verify that it reaches a global optimum by plotting the objective function.</p><p>The reason for using <code>BlackBoxOptim.jl</code> is that this package was the most suitable for our model. After trying several optimization packages in Python and Julia, <code>BlackBoxOptim.jl</code> consistently found the optimum values most reliably. A downside of DE algorithms like <code>BlackBoxOptim.jl</code> is that they can have high computational costs. If the computational cost is excessively high to you, you can reduce it by setting <code>populationsize</code> or <code>maxiter</code> options in <code>tuning_hyperparameter</code> to lower values. However, this may lead to a decrease in model performance.</p><h4 id="Range-of-Data-over-which-the-Marginal-Likelihood-is-Calculated"><a class="docs-heading-anchor" href="#Range-of-Data-over-which-the-Marginal-Likelihood-is-Calculated">Range of Data over which the Marginal Likelihood is Calculated</a><a id="Range-of-Data-over-which-the-Marginal-Likelihood-is-Calculated-1"></a><a class="docs-heading-anchor-permalink" href="#Range-of-Data-over-which-the-Marginal-Likelihood-is-Calculated" title="Permalink"></a></h4><p>In Bayesian methodology, the standard criterion of the model comparison is the marginal likelihood. When we compare models using the marginal likelihood, the most crucial prerequisite is that the marginal likelihoods of all models must be calculated over the same observations.</p><p>For instance, let&#39;s say we have <code>data</code> with the number of rows being 100. Model 1 has <code>p=1</code>, and Model 2 has <code>p=2</code>. In this case, the marginal likelihood should be computed over <code>data[3:end, :]</code>. This means that for Model 1, <code>data[2, :]</code> is used as the initial value, and for Model 2, <code>data[1:2, :]</code> is used as initial values. <code>tuning_hyperparameter</code> automatically reflects this fact by calculating the marginal likelihood over <code>data[upper_p+1:end, :]</code> for model comparison.</p><h4 id="Prior-Belief-about-the-Expectation-Hypothesis"><a class="docs-heading-anchor" href="#Prior-Belief-about-the-Expectation-Hypothesis">Prior Belief about the Expectation Hypothesis</a><a id="Prior-Belief-about-the-Expectation-Hypothesis-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Belief-about-the-Expectation-Hypothesis" title="Permalink"></a></h4><p>Our algorithm has an inductive bias that the estimates should not deviate too much from the Expectation Hypothesis (EH). Here, the assumed EH means that the term premium is a non-zero constant. If you want to introduce an inductive bias centered around the pure EH, where the term premium is zero, set <code>is_pure_EH=true</code>. However, note that using this option may take some initial time to numerically set the prior distribution.</p><h2 id="Step-2.-Sampling-the-Posterior-Distribution-of-Parameters"><a class="docs-heading-anchor" href="#Step-2.-Sampling-the-Posterior-Distribution-of-Parameters">Step 2. Sampling the Posterior Distribution of Parameters</a><a id="Step-2.-Sampling-the-Posterior-Distribution-of-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2.-Sampling-the-Posterior-Distribution-of-Parameters" title="Permalink"></a></h2><p>In Step 1, we got <code>tuned::Hyperparameter</code>. <a href="../api/#TermStructureModels.posterior_sampler-Tuple{Any, Any, Any, Any, Any, Hyperparameter}"><code>posterior_sampler</code></a> uses it for the estimation.</p><pre><code class="language-julia hljs">saved_params, acceptPrMH = posterior_sampler(yields, macros, tau_n, rho, iteration, tuned::Hyperparameter;
                                            medium_tau=collect(24:3:48),
                                            init_param=[],
                                            psi=[],
                                            psi_const=[],
                                            gamma_bar=[],
                                            kappaQ_prior_pr=[],
                                            mean_kQ_infty=0,
                                            std_kQ_infty=0.1,
                                            fix_const_PC1=false,
                                            data_scale=1200)</code></pre><p>If users changed the default values in Step 1, the corresponding default values in the above function also should be changed. If users use our default values, the function simplifies to</p><pre><code class="language-julia hljs">saved_params, acceptPrMH = posterior_sampler(yields, macros, tau_n, rho, iteration, tuned::Hyperparameter)</code></pre><p><code>iteration</code> is the number of posterior samples that users want to get. Our MCMC starts at the prior mean, and you have to erase burn-in samples manually.</p><p><code>saved_params::Vector{Parameter}</code> has a length of <code>iteration</code> and each entry is a posterior sample. <code>acceptPrMH</code> is <code>dQ+1</code>-Vector, and the <code>i(&lt;=dQ)</code>-th entry shows the MH acceptance rate for i-th principal component in the recursive <span>$\mathbb{P}$</span>-VAR. The last entry of <code>acceptPrMH</code> is the MH acceptance rate for <code>kappaQ</code> under the unrestricted JSZ model. It is zero under the AFNS restriction.</p><h2 id="Step-3.-Discard-Burn-in-and-Nonstationary-Posterior-Samples"><a class="docs-heading-anchor" href="#Step-3.-Discard-Burn-in-and-Nonstationary-Posterior-Samples">Step 3. Discard Burn-in and Nonstationary Posterior Samples</a><a id="Step-3.-Discard-Burn-in-and-Nonstationary-Posterior-Samples-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3.-Discard-Burn-in-and-Nonstationary-Posterior-Samples" title="Permalink"></a></h2><p>After users get posterior samples(<code>saved_params</code>), they might want to discard some samples as burn-in. If the number of burn-in samples is <code>burnin</code>, run</p><pre><code class="language-julia hljs">saved_params = saved_params[burnin+1:end]</code></pre><p>Also, users might want to erase posterior samples that do not satisfies the stationary condition. It can be done by <a href="../api/#TermStructureModels.erase_nonstationary_param-Tuple{Any}"><code>erase_nonstationary_param</code></a>.</p><pre><code class="language-julia hljs">saved_params, Pr_stationary = erase_nonstationary_param(saved_params; threshold=1)</code></pre><p>All entries in the first output (<code>saved_params::Vector{Parameter}</code>) are posterior samples that satisfy the stationary condition.</p><div class="admonition is-warning"><header class="admonition-header">Reduction in the Number of Posterior Samples</header><div class="admonition-body"><p>The vector length of <code>saved_params</code> decreases after the burn-in process and <code>erase_nonstationary_param</code>. Note that this leads to a gap between <code>iteration</code> and <code>length(saved_params)</code>.</p></div></div><div class="admonition is-info"><header class="admonition-header">Handling Non-Stationary Data</header><div class="admonition-body"><p>The optional input <code>eigenvalue</code> is designed to discard posterior samples with eigenvalues of the VAR system exceeding the specified threshold. Traditionally, we use a stationary VAR, so the default threshold is set to <code>1</code>. However, for non-stationary VAR models, it may be necessary to allow for a slightly higher threshold. In such cases, you can set <code>threshold</code> to a value greater than <code>1</code>, such as <code>1.05</code>.</p></div></div><h2 id="Diagnostics-for-MCMC"><a class="docs-heading-anchor" href="#Diagnostics-for-MCMC">Diagnostics for MCMC</a><a id="Diagnostics-for-MCMC-1"></a><a class="docs-heading-anchor-permalink" href="#Diagnostics-for-MCMC" title="Permalink"></a></h2><p>We believe in the efficiency of our algorithm, so users do not need to be overly concerned about the convergence of the posterior samples. In our opinion, sampling 6,000 posterior samples and erase the first 1,000 samples as burn-in would be enough.</p><p>We provide <a href="https://econpreference.github.io/TermStructureModels.jl/dev/api/#TermStructureModels.ineff_factor-Tuple{Any}">a measure</a> to gauge the efficiency of the algorithm, that is</p><pre><code class="language-julia hljs">ineff = ineff_factor(saved_params)</code></pre><p><code>saved_params::Vector{Parameter}</code> is the output of <code>posterior_sampler</code>. <code>ineff</code> is <code>Tuple(kappaQ, kQ_infty, gamma, SigmaO, varFF, phi)</code>. Each object of the tuple has the same shape as its corresponding parameter. The entries of the <code>Array</code> of the <code>Tuple</code> represent the inefficiency factors of the corresponding parameters. If an inefficiency factor is high, it indicates poor sampling efficiency of the parameter located at the same position.</p><p>You can calculate the maximum inefficiency factor by</p><pre><code class="language-julia hljs">max_ineff = (ineff[1] |&gt; maximum, ineff[2], ineff[3] |&gt; maximum, ineff[4] |&gt; maximum, ineff[5] |&gt; maximum, ineff[6] |&gt; maximum) |&gt; maximum</code></pre><p>The value obtained by dividing the number of posterior samples by <code>max_ineff</code> is the effective number of posterior samples, taking into account the efficiency of the sampler. For example, let&#39;s say <code>max_ineff = 10</code>. Then, if 6,000 posterior samples are drawn and the first 1,000 samples are erased as burn-in, the remaining 5,000 posterior samples have the same efficiency as using 500 i.i.d samples, calculated as <code>(6000-1000)/max_ineff</code>. For reference, in <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4708628">our paper</a>, the maximum inefficiency factor was <code>2.38</code>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../notations/">« Notations</a><a class="docs-footer-nextpage" href="../inference/">Statistical Inference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Tuesday 4 March 2025 02:01">Tuesday 4 March 2025</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
