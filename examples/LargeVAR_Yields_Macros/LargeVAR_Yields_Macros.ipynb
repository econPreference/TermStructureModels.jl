{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Estimating a Large VAR Term Structure Model with Macroeconomic Variables\n",
    "\n",
    "This notebook provides an example of how to use the TermStructureModels.jl package to estimate a large vector autoregression of the yield curve with macroeconomic variables. The procedure of the algorithm is as follows.\n",
    "\n",
    "1. Data and Settings\n",
    "2. Optimization of Hyperparameters\n",
    "3. Estimation\n",
    "4. Statistical Inferences: Yield Curve Interpolation, Posterior Distribution of Parameters, Term Premiums\n",
    "5. Scenario Analysis\n",
    "\n",
    "You need to download two data files([\"current.csv\"](https://github.com/econPreference/TermStructureModels.jl/blob/main/examples/LargeVAR_Yields_Macros/current.csv) and [\"LW_monthly.xlsx\"](https://github.com/econPreference/TermStructureModels.jl/blob/main/examples/LargeVAR_Yields_Macros/LW_monthly.xlsx)). The data files and this notebook must be in the same directory. \"current.csv\" contains macroeconomic data, and \"LW_monthly.xlsx\" contains bond yields data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Settings\n",
    "\n",
    "### Packages\n",
    "\n",
    "First, load the necessary packages. If you need to install the packages, run\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "\n",
    "Pkg.add(\"TermStructureModels\")\n",
    "Pkg.add([\"CSV\", \"Dates\", \"DataFrames\", \"XLSX\", \"JLD2\"])\n",
    "\n",
    "Pkg.instantiate()\n",
    "Pkg.precompile()\n",
    "```\n",
    "\n",
    "After installing the packages, run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "Pkg.precompile()\n",
    "\n",
    "using TermStructureModels\n",
    "using CSV, Dates, DataFrames, XLSX, JLD2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "**Note:** You do not have to understand this Data section. Load the data using your preferred method. The essential variables that need to be set in this section are `tau_n`, `rho`, `macros`, and `yields`.\n",
    "\n",
    "`date_start` and `date_end` define the start and end dates of the dataset. `tau_n` is a Vector that contains maturities of the yield data. `data_loading` is a function to load yield and macro data.\n",
    "\n",
    "`sdate` is also a function you do not need to use. This function is merely a convenience for fetching observations at the desired points in time. For example, if you want to load macro data from May to July 2001, you can do so by executing `macros[sdate(2001,5):sdate(2001,7), :]`.\n",
    "\n",
    "The package requires `yields::Matrix` and `macros::Matrix`, but, in this code, we have `yields::DataFrame` and `macros::DataFrame`. It may be more convenient for you to set your data as struct `Matrix`. Also, note that the first columns of the `yields` and `macros` are date variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = Date(\"1987-01-01\", \"yyyy-mm-dd\") |> x -> x - Month(18 + 2)\n",
    "date_end = Date(\"2022-12-01\", \"yyyy-mm-dd\")\n",
    "\n",
    "tau_n = [1; 3; 6; 9; collect(12:6:60); collect(72:12:120)]\n",
    "function data_loading(; date_start, date_end, tau_n)\n",
    "\n",
    "    ## Macro data\n",
    "    raw_fred = CSV.File(\"current.csv\") |> DataFrame |> x -> x[314:769, :]\n",
    "    raw_fred = [Date.(raw_fred[:, 1], DateFormat(\"mm/dd/yyyy\")) raw_fred[:, 2:end]]\n",
    "    raw_fred = raw_fred[findall(x -> x == yearmonth(date_start), yearmonth.(raw_fred[:, 1]))[1]:findall(x -> x == yearmonth(date_end), yearmonth.(raw_fred[:, 1]))[1], :]\n",
    "\n",
    "    excluded = [\"FEDFUNDS\", \"CP3Mx\", \"TB3MS\", \"TB6MS\", \"GS1\", \"GS5\", \"GS10\", \"TB3SMFFM\", \"TB6SMFFM\", \"T1YFFM\", \"T5YFFM\", \"T10YFFM\", \"COMPAPFFx\", \"AAAFFM\", \"BAAFFM\"]\n",
    "    macros = raw_fred[:, findall(x -> !(x ∈ excluded), names(raw_fred))]\n",
    "    idx = ones(Int, 1)\n",
    "    for i in axes(macros[:, 2:end], 2)\n",
    "        if sum(ismissing.(macros[:, i+1])) == 0\n",
    "            push!(idx, i + 1)\n",
    "        end\n",
    "    end\n",
    "    macros = macros[:, idx]\n",
    "    excluded = [\"W875RX1\", \"IPFPNSS\", \"IPFINAL\", \"IPCONGD\", \"IPDCONGD\", \"IPNCONGD\", \"IPBUSEQ\", \"IPMAT\", \"IPDMAT\", \"IPNMAT\", \"IPMANSICS\", \"IPB51222S\", \"IPFUELS\", \"HWIURATIO\", \"CLF16OV\", \"CE16OV\", \"UEMPLT5\", \"UEMP5TO14\", \"UEMP15OV\", \"UEMP15T26\", \"UEMP27OV\", \"USGOOD\", \"CES1021000001\", \"USCONS\", \"MANEMP\", \"DMANEMP\", \"NDMANEMP\", \"SRVPRD\", \"USTPU\", \"USWTRADE\", \"USTRADE\", \"USFIRE\", \"USGOVT\", \"AWOTMAN\", \"AWHMAN\", \"CES2000000008\", \"CES3000000008\", \"HOUSTNE\", \"HOUSTMW\", \"HOUSTS\", \"HOUSTW\", \"PERMITNE\", \"PERMITMW\", \"PERMITS\", \"PERMITW\", \"NONBORRES\", \"DTCOLNVHFNM\", \"AAAFFM\", \"BAAFFM\", \"EXSZUSx\", \"EXJPUSx\", \"EXUSUKx\", \"EXCAUSx\", \"WPSFD49502\", \"WPSID61\", \"WPSID62\", \"CPIAPPSL\", \"CPITRNSL\", \"CPIMEDSL\", \"CUSR0000SAC\", \"CUSR0000SAS\", \"CPIULFSL\", \"CUSR0000SA0L2\", \"CUSR0000SA0L5\", \"DDURRG3M086SBEA\", \"DNDGRG3M086SBEA\", \"DSERRG3M086SBEA\"]\n",
    "    push!(excluded, \"CMRMTSPLx\", \"RETAILx\", \"HWI\", \"UEMPMEAN\", \"CLAIMSx\", \"AMDMNOx\", \"ANDENOx\", \"AMDMUOx\", \"BUSINVx\", \"ISRATIOx\", \"BUSLOANS\", \"NONREVSL\", \"CONSPI\", \"S&P: indust\", \"S&P div yield\", \"S&P PE ratio\", \"M1SL\", \"BOGMBASE\")\n",
    "    macros = macros[:, findall(x -> !(x ∈ excluded), names(macros))]\n",
    "    macros = [macros[:, 1] Float64.(macros[:, 2:end])]\n",
    "    rename!(macros, Dict(:x1 => \"date\"))\n",
    "    raw_macros = deepcopy(macros)\n",
    "\n",
    "    rho = Vector{Float64}(undef, size(macros[:, 2:end], 2))\n",
    "    is_percent = fill(false, size(macros[:, 2:end], 2))\n",
    "    idx_diff = Vector{Float64}(undef, size(macros[:, 2:end], 2))\n",
    "    logmacros = similar(macros[:, 2:end] |> Array)\n",
    "    for i in axes(macros[:, 2:end], 2) # i'th macro variable (excluding date)\n",
    "        logmacros[:, i] = 100log.(macros[:, i+1])\n",
    "\n",
    "        if names(macros[:, 2:end])[i] ∈ [\"CUMFNS\", \"UNRATE\", \"AAA\", \"BAA\"]\n",
    "            is_percent[i] = true\n",
    "        end\n",
    "\n",
    "        if names(macros[:, 2:end])[i] ∈ [\"AAA\", \"BAA\"]\n",
    "            macros[2:end, i+1] = macros[2:end, i+1] - macros[1:end-1, i+1]\n",
    "            rho[i] = 0.0\n",
    "            idx_diff[i] = 1\n",
    "        elseif names(macros[:, 2:end])[i] ∈ [\"CUMFNS\", \"UNRATE\"]\n",
    "            rho[i] = 1.0\n",
    "            idx_diff[i] = 0\n",
    "        elseif names(macros[:, 2:end])[i] ∈ [\"CES0600000007\", \"VIXCLSx\"]\n",
    "            macros[:, i+1] = log.(macros[:, i+1]) |> x -> 100 * x\n",
    "            rho[i] = 1.0\n",
    "            idx_diff[i] = 0\n",
    "        else\n",
    "            macros[2:end, i+1] = log.(macros[2:end, i+1]) - log.(macros[1:end-1, i+1]) |> x -> 1200 * x\n",
    "            rho[i] = 0.0\n",
    "            idx_diff[i] = 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    raw_macros = raw_macros[3:end, :]\n",
    "    macros = macros[3:end, :]\n",
    "    logmacros = logmacros[3:end, :]\n",
    "    mean_macros = mean(macros[:, 2:end] |> Array, dims=1)[1, :]\n",
    "    macros[:, 2:end] .-= mean_macros'\n",
    "\n",
    "    ## Yield data\n",
    "    raw_yield = XLSX.readdata(\"LW_monthly.xlsx\", \"Sheet1\", \"A293:DQ748\") |> x -> [Date.(string.(x[:, 1]), DateFormat(\"yyyymm\")) convert(Matrix{Float64}, x[:, tau_n.+1])] |> x -> DataFrame(x, [\"date\"; [\"Y$i\" for i in tau_n]])\n",
    "    yields = raw_yield[findall(x -> x == yearmonth(date_start), yearmonth.(raw_yield[:, 1]))[1]:findall(x -> x == yearmonth(date_end), yearmonth.(raw_yield[:, 1]))[1], :]\n",
    "    yields = yields[3:end, :]\n",
    "\n",
    "    yields = [Date.(string.(yields[:, 1]), DateFormat(\"yyyy-mm-dd\")) Float64.(yields[:, 2:end])]\n",
    "    rename!(yields, Dict(:x1 => \"date\"))\n",
    "\n",
    "    return rho, is_percent, idx_diff, logmacros, raw_macros, macros, mean_macros, yields\n",
    "end\n",
    "rho, is_percent, idx_diff, logmacros, raw_macros, macros, mean_macros, yields = data_loading(; date_start, date_end, tau_n)\n",
    "\n",
    "sdate(yy, mm) = findall(x -> x == Date(yy, mm), macros[:, 1])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Currently, the package requires the number of spanned factors to be exactly three(`dQ = 3`). However, anticipating the possibility of relaxing this constraint in the future, the number of factors has been generalized through `dimQ()`. `dP` is the sum of `dQ` and the number of macro variables. `medium_tau` and `std_kQ_infty` are set based on prior belief.\n",
    "\n",
    "`iteration` is the total length of the MCMC, and `burnin` is the size of burn-in. `TP_tau = [24, 120]` indicates that the term premiums of the 2-year(24 months) and 10-year(120 months) bonds are estimated. `TP_tau` should be a `Vector`. So, if you want to estimate only a single maturity term premium, set `TP_tau` as a `Vector` of length `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ = dimQ()\n",
    "dP = size(macros, 2) - 1 + dQ\n",
    "medium_tau = collect(36:42)\n",
    "std_kQ_infty = 0.2\n",
    "\n",
    "iteration = 25_000\n",
    "burnin = 5_000\n",
    "TP_tau = [24, 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip.** If you want to reduce computation time, modify the `iteration` and `burnin` as follows.\n",
    "\n",
    "```julia\n",
    "iteration = 2_000\n",
    "burnin = 500\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write scenarios\n",
    "\n",
    "`scenario_TP = [12, 24, 60, 120]` indicates that term premiums of one, two, five, and ten-year bonds are predicted. `scenario_horizon` is the forecasting horizon. `gen_scene(idx_case)` generates `Vector{Scenario}` based on the scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_TP = [12, 24, 60, 120]\n",
    "scenario_horizon = 60\n",
    "function gen_scene(idx_case)\n",
    "\n",
    "    if idx_case == 1\n",
    "        scene = Vector{Scenario}(undef, 36)\n",
    "        for h in 1:36\n",
    "            combs = zeros(1, dP - dQ + length(tau_n))\n",
    "            vals = [0.0]\n",
    "            scene[h] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        end\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [5.1]\n",
    "        scene[12] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [4.1]\n",
    "        scene[24] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [3.1]\n",
    "        scene[end] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        return scene\n",
    "    elseif idx_case == 2\n",
    "        scene = Vector{Scenario}(undef, 10)\n",
    "        VIX_path = raw_macros[sdate(2008, 9):sdate(2009, 6), end]\n",
    "        for h in 1:10\n",
    "            combs = zeros(1, dP - dQ + length(tau_n))\n",
    "            vals = zeros(size(combs, 1))\n",
    "\n",
    "            combs[1, end] = 1.0\n",
    "            vals[1] = 100log(VIX_path[h]) - mean_macros[end]\n",
    "            scene[h] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        end\n",
    "        return scene\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optimization of Hyperparameters](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Step-1.-Tuning-Hyperparameters)\n",
    "\n",
    "Hyperparameters are optimized by running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned, opt = tuning_hyperparameter(Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n, rho; std_kQ_infty, medium_tau)\n",
    "p = tuned.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`yields[:, 2:end]` and `macros[:, 2:end]` erase the first columns(date variables). `Array` transforms `DataFrame` to `Matrix`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Estimation](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Step-2.-Sampling-the-Posterior-Distribution-of-Parameters)\n",
    "\n",
    "To get posterior samples of parameters, run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params, acceptPrMH = posterior_sampler(Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n, rho, iteration, tuned; medium_tau, std_kQ_infty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the MCMC simulation, do the burn-in procedure. And then, erase posterior samples that do not satisfy the stationary condition. These works can be done by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params = saved_params[burnin+1:end]\n",
    "iteration = length(saved_params)\n",
    "\n",
    "saved_params, Pr_stationary = erase_nonstationary_param(saved_params)\n",
    "iteration = length(saved_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, `iteration` represents the number of remaining posterior samples. Therefore, it needs to be adjusted when some samples are discarded.\n",
    "\n",
    "Lastly, [calculate the inefficiency factors](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Diagnostics-for-MCMC) by running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineff = ineff_factor(saved_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Inferences\n",
    "\n",
    "To get [posterior samples of parameters](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Inference-for-Parameters) in the term structure model, run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_params = reducedform(saved_params, Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yield curve interpolations](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Yield-Curve-Interpolation) can be done by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_latent_params = latentspace(saved_params, Array(yields[:, 2:end]), tau_n)\n",
    "fitted_yields = fitted_YieldCurve(collect(1:tau_n[end]), saved_latent_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first input of `fitted_YieldCurve` specifies the maturities for which you want to compute the fitted yields.\n",
    "\n",
    "Lastly, [the term premium](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Term-Premiums) is calculated by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_sub = (ineff[1] |> maximum, ineff[2], ineff[3] |> maximum, ineff[4] |> maximum, ineff[5] |> maximum, ineff[6] |> maximum) |> maximum |> ceil |> Int\n",
    "saved_TP = term_premium(TP_tau, tau_n, saved_params[1:iter_sub:end], Array(yields[:, 2:end]), Array(macros[:, 2:end]))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iter_sub` is the ceiling of the maximum inefficiency factor, and `saved_params[1:iter_sub:end]` is the subsampling. Considering computational cost, posterior samples of the term premium are drawn using only a subset of the posterior samples.\n",
    "\n",
    "There's no need to keep `saved_TP` in memory, so it's beneficial to store it on a storage device and free up memory space. This can be done with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD2.save(\"TP.jld2\", \"TP\", saved_TP)\n",
    "TP = nothing\n",
    "# GC.gc() # It's better to let the garbage collector work automatically, so we remove this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is referred to as \"Garbage Collection\". `saved_TP` stored in \"TP.jld2\" can be loaded through\n",
    "\n",
    "```julia\n",
    "saved_TP = JLD2.load(\"TP.jld2\")[\"TP\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Forecasting](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Forecasting)\n",
    "\n",
    "### [Baseline Forecasts](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Baseline-Forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = conditional_expectation([], scenario_TP, scenario_horizon, saved_params[1:iter_sub:end], Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n; mean_macros)\n",
    "\n",
    "JLD2.save(\"uncond_scenario.jld2\", \"projections\", projections)\n",
    "projections = nothing\n",
    "# GC.gc() # It's better to let the garbage collector work automatically, so we remove this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also performs the garbage collection. `projections` stored in \"uncond_scenario.jld2\" can be loaded through\n",
    "\n",
    "```julia\n",
    "projections = JLD2.load(\"uncond_scenario.jld2\")[\"projections\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Scenario Forecasts](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Scenario-Forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:2\n",
    "    projections = conditional_expectation(gen_scene(i), scenario_TP, scenario_horizon, saved_params[1:iter_sub:end], Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n; mean_macros)\n",
    "\n",
    "    JLD2.save(\"scenario$i.jld2\", \"projections\", projections)\n",
    "    projections = nothing\n",
    "    # GC.gc() # It's better to let the garbage collector work automatically, so we remove this line.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three lines are the garbage collection. You can load saved `projections` through `JLD2.load`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
