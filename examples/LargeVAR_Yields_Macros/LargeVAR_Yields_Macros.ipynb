{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code for Paper \"A Large Vector Autoregression of the Yield Curve and Macroeconomic Variables with No-Arbitrage Restriction\"\n",
    "\n",
    "This notebook explains how we estimated the term structure model for [our paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4708628). The procedure of the algorithm is as follows.\n",
    "\n",
    "1. Data and Settings\n",
    "2. Optimization of Hyperparameters\n",
    "3. Estimation\n",
    "4. Statistical Inferences: Yield Curve Interpolation, Posterior Distribution of Parameters, Term Premiums\n",
    "5. Scenario Analysis\n",
    "\n",
    "You need to download two data files([\"current.csv\"](https://github.com/econPreference/TermStructureModels.jl/blob/main/examples/LargeVAR_Yields_Macros/current.csv) and [\"LW_monthly.xlsx\"](https://github.com/econPreference/TermStructureModels.jl/blob/main/examples/LargeVAR_Yields_Macros/LW_monthly.xlsx)). The data files and this notebook must be located in the same location. \"current.csv\" contains macroeconomic data, and \"LW_monthly.xlsx\" contains bond yields data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Settings\n",
    "\n",
    "### Packages\n",
    "\n",
    "First, load the necessary packages. If you need to install the packages, run\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "\n",
    "Pkg.add(\"TermStructureModels\")\n",
    "Pkg.add([\"CSV\", \"Dates\", \"DataFrames\", \"XLSX\", \"JLD2\"])\n",
    "\n",
    "Pkg.instantiate()\n",
    "Pkg.precompile()\n",
    "```\n",
    "\n",
    "After installing the packages, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "Pkg.precompile()\n",
    "\n",
    "using TermStructureModels\n",
    "using CSV, Dates, DataFrames, XLSX, JLD2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "**Note:** You do not have to understand this Data section. Load the data using your preferred method. The essential variables that need to be set in this section are `tau_n`, `rho`, `macros`, and `yields`. \n",
    "\n",
    "`date_start` and `date_end` define the start and end dates of our dataset. `tau_n` is a Vector that contains maturities of our yield data. `data_loading` is a function to load yield and macro data. \n",
    "\n",
    "`sdate` is also a function you do not need to use. This function is merely a convenience for fetching observations at the desired points in time. For example, if you want to load macro data from May to July 2001, you can do so by executing `macros[sdate(2001,5):sdate(2001,7), :]`.\n",
    "\n",
    "Our package requires `yields::Matrix` and `macros::Matrix`, but, in this code, we have `yields::DataFrame` and `macros::DataFrame`. It may be more convenient for users to set their data as struct `Matrix`. Also, note that the first columns of our `yields` and `macros` are date variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = Date(\"1987-01-01\", \"yyyy-mm-dd\") |> x -> x - Month(18 + 2)\n",
    "date_end = Date(\"2022-12-01\", \"yyyy-mm-dd\")\n",
    "\n",
    "tau_n = [1; 3; 6; 9; collect(12:6:60); collect(72:12:120)]\n",
    "function data_loading(; date_start, date_end, tau_n)\n",
    "\n",
    "    ## Macro data\n",
    "    raw_fred = CSV.File(\"current.csv\") |> DataFrame |> x -> x[314:769, :]\n",
    "    raw_fred = [Date.(raw_fred[:, 1], DateFormat(\"mm/dd/yyyy\")) raw_fred[:, 2:end]]\n",
    "    raw_fred = raw_fred[findall(x -> x == yearmonth(date_start), yearmonth.(raw_fred[:, 1]))[1]:findall(x -> x == yearmonth(date_end), yearmonth.(raw_fred[:, 1]))[1], :]\n",
    "\n",
    "    excluded = [\"FEDFUNDS\", \"CP3Mx\", \"TB3MS\", \"TB6MS\", \"GS1\", \"GS5\", \"GS10\", \"TB3SMFFM\", \"TB6SMFFM\", \"T1YFFM\", \"T5YFFM\", \"T10YFFM\", \"COMPAPFFx\", \"AAAFFM\", \"BAAFFM\"]\n",
    "    macros = raw_fred[:, findall(x -> !(x ∈ excluded), names(raw_fred))]\n",
    "    idx = ones(Int, 1)\n",
    "    for i in axes(macros[:, 2:end], 2)\n",
    "        if sum(ismissing.(macros[:, i+1])) == 0\n",
    "            push!(idx, i + 1)\n",
    "        end\n",
    "    end\n",
    "    macros = macros[:, idx]\n",
    "    excluded = [\"W875RX1\", \"IPFPNSS\", \"IPFINAL\", \"IPCONGD\", \"IPDCONGD\", \"IPNCONGD\", \"IPBUSEQ\", \"IPMAT\", \"IPDMAT\", \"IPNMAT\", \"IPMANSICS\", \"IPB51222S\", \"IPFUELS\", \"HWIURATIO\", \"CLF16OV\", \"CE16OV\", \"UEMPLT5\", \"UEMP5TO14\", \"UEMP15OV\", \"UEMP15T26\", \"UEMP27OV\", \"USGOOD\", \"CES1021000001\", \"USCONS\", \"MANEMP\", \"DMANEMP\", \"NDMANEMP\", \"SRVPRD\", \"USTPU\", \"USWTRADE\", \"USTRADE\", \"USFIRE\", \"USGOVT\", \"AWOTMAN\", \"AWHMAN\", \"CES2000000008\", \"CES3000000008\", \"HOUSTNE\", \"HOUSTMW\", \"HOUSTS\", \"HOUSTW\", \"PERMITNE\", \"PERMITMW\", \"PERMITS\", \"PERMITW\", \"NONBORRES\", \"DTCOLNVHFNM\", \"AAAFFM\", \"BAAFFM\", \"EXSZUSx\", \"EXJPUSx\", \"EXUSUKx\", \"EXCAUSx\", \"WPSFD49502\", \"WPSID61\", \"WPSID62\", \"CPIAPPSL\", \"CPITRNSL\", \"CPIMEDSL\", \"CUSR0000SAC\", \"CUSR0000SAS\", \"CPIULFSL\", \"CUSR0000SA0L2\", \"CUSR0000SA0L5\", \"DDURRG3M086SBEA\", \"DNDGRG3M086SBEA\", \"DSERRG3M086SBEA\"]\n",
    "    push!(excluded, \"CMRMTSPLx\", \"RETAILx\", \"HWI\", \"UEMPMEAN\", \"CLAIMSx\", \"AMDMNOx\", \"ANDENOx\", \"AMDMUOx\", \"BUSINVx\", \"ISRATIOx\", \"BUSLOANS\", \"NONREVSL\", \"CONSPI\", \"S&P: indust\", \"S&P div yield\", \"S&P PE ratio\", \"M1SL\", \"BOGMBASE\")\n",
    "    macros = macros[:, findall(x -> !(x ∈ excluded), names(macros))]\n",
    "    macros = [macros[:, 1] Float64.(macros[:, 2:end])]\n",
    "    rename!(macros, Dict(:x1 => \"date\"))\n",
    "    raw_macros = deepcopy(macros)\n",
    "\n",
    "    rho = Vector{Float64}(undef, size(macros[:, 2:end], 2))\n",
    "    is_percent = fill(false, size(macros[:, 2:end], 2))\n",
    "    idx_diff = Vector{Float64}(undef, size(macros[:, 2:end], 2))\n",
    "    logmacros = similar(macros[:, 2:end] |> Array)\n",
    "    for i in axes(macros[:, 2:end], 2) # i'th macro variable (excluding date)\n",
    "        logmacros[:, i] = 100log.(macros[:, i+1])\n",
    "\n",
    "        if names(macros[:, 2:end])[i] ∈ [\"CUMFNS\", \"UNRATE\", \"AAA\", \"BAA\"]\n",
    "            is_percent[i] = true\n",
    "        end\n",
    "\n",
    "        if names(macros[:, 2:end])[i] ∈ [\"AAA\", \"BAA\"]\n",
    "            macros[2:end, i+1] = macros[2:end, i+1] - macros[1:end-1, i+1]\n",
    "            rho[i] = 0.0\n",
    "            idx_diff[i] = 1\n",
    "        elseif names(macros[:, 2:end])[i] ∈ [\"CUMFNS\", \"UNRATE\"]\n",
    "            rho[i] = 1.0\n",
    "            idx_diff[i] = 0\n",
    "        elseif names(macros[:, 2:end])[i] ∈ [\"CES0600000007\", \"VIXCLSx\"]\n",
    "            macros[:, i+1] = log.(macros[:, i+1]) |> x -> 100 * x\n",
    "            rho[i] = 1.0\n",
    "            idx_diff[i] = 0\n",
    "        else\n",
    "            macros[2:end, i+1] = log.(macros[2:end, i+1]) - log.(macros[1:end-1, i+1]) |> x -> 1200 * x\n",
    "            rho[i] = 0.0\n",
    "            idx_diff[i] = 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    raw_macros = raw_macros[3:end, :]\n",
    "    macros = macros[3:end, :]\n",
    "    logmacros = logmacros[3:end, :]\n",
    "    mean_macros = mean(macros[:, 2:end] |> Array, dims=1)[1, :]\n",
    "    macros[:, 2:end] .-= mean_macros'\n",
    "\n",
    "    ## Yield data\n",
    "    raw_yield = XLSX.readdata(\"LW_monthly.xlsx\", \"Sheet1\", \"A293:DQ748\") |> x -> [Date.(string.(x[:, 1]), DateFormat(\"yyyymm\")) convert(Matrix{Float64}, x[:, tau_n.+1])] |> x -> DataFrame(x, [\"date\"; [\"Y$i\" for i in tau_n]])\n",
    "    yields = raw_yield[findall(x -> x == yearmonth(date_start), yearmonth.(raw_yield[:, 1]))[1]:findall(x -> x == yearmonth(date_end), yearmonth.(raw_yield[:, 1]))[1], :]\n",
    "    yields = yields[3:end, :]\n",
    "\n",
    "    yields = [Date.(string.(yields[:, 1]), DateFormat(\"yyyy-mm-dd\")) Float64.(yields[:, 2:end])]\n",
    "    rename!(yields, Dict(:x1 => \"date\"))\n",
    "\n",
    "    return rho, is_percent, idx_diff, logmacros, raw_macros, macros, mean_macros, yields\n",
    "end\n",
    "rho, is_percent, idx_diff, logmacros, raw_macros, macros, mean_macros, yields = data_loading(; date_start, date_end, tau_n)\n",
    "\n",
    "sdate(yy, mm) = findall(x -> x == Date(yy, mm), macros[:, 1])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Currently, our package requires the number of spanned factors to be exactly three(`dQ = 3`). However, anticipating the possibility of relaxing this constraint in the future, we have generalized the number of factors through `dimQ()`. `dP` is the sum of `dQ` and the number of macro variables. We set `medium_tau` and `std_kQ_infty` based on our belief.\n",
    "\n",
    "`iteration` is the total length of our MCMC, and `burnin` is the size of burn-in. `TP_tau = 120` indicates that we estimate the term premium of the 10-year(120 months) bond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ = dimQ()\n",
    "dP = size(macros, 2) - 1 + dQ\n",
    "medium_tau = collect(36:42)\n",
    "std_kQ_infty = 0.2\n",
    "\n",
    "iteration = 25_000\n",
    "burnin = 5_000\n",
    "TP_tau = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip.** If you want to reduce computation time, modify the `iteration` and `burnin` as follows.\n",
    "```julia\n",
    "iteration = 2_000\n",
    "burnin = 500\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write scenarios\n",
    "\n",
    "`scenario_TP = [12, 24, 60, 120]` says that we predict term premiums of one, two, five, and ten-year bonds. `scenario_horizon` is the forecasting horizon. `gen_scene(idx_case)` generates `Vector{Scenario}` based on our scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_TP = [12, 24, 60, 120]\n",
    "scenario_horizon = 60\n",
    "function gen_scene(idx_case)\n",
    "\n",
    "    if idx_case == 1\n",
    "        scene = Vector{Scenario}(undef, 36)\n",
    "        for h in 1:36\n",
    "            combs = zeros(1, dP - dQ + length(tau_n))\n",
    "            vals = [0.0]\n",
    "            scene[h] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        end\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [5.1]\n",
    "        scene[12] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [4.1]\n",
    "        scene[24] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "\n",
    "        combs = [1 zeros(1, dP - dQ + length(tau_n) - 1)]\n",
    "        vals = [3.1]\n",
    "        scene[end] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        return scene\n",
    "    elseif idx_case == 2\n",
    "        scene = Vector{Scenario}(undef, 10)\n",
    "        VIX_path = raw_macros[sdate(2008, 9):sdate(2009, 6), end]\n",
    "        for h in 1:10\n",
    "            combs = zeros(1, dP - dQ + length(tau_n))\n",
    "            vals = zeros(size(combs, 1))\n",
    "\n",
    "            combs[1, end] = 1.0\n",
    "            vals[1] = 100log(VIX_path[h]) - mean_macros[end]\n",
    "            scene[h] = Scenario(combinations=deepcopy(combs), values=deepcopy(vals))\n",
    "        end\n",
    "        return scene\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optimization of Hyperparameters](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Step-1.-Tuning-Hyperparameters)\n",
    "\n",
    "We optimize hyperparameters by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned, opt = tuning_hyperparameter(Array(yields[:, 2:end]), Array(macros[:, 2:end]), tau_n, rho; std_kQ_infty, medium_tau)\n",
    "p = tuned.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`yields[:, 2:end]` and `macros[:, 2:end]` erase the first columns(date variables). `Array` transforms `DataFrame` to `Matrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Estimation](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Step-2.-Sampling-the-Posterior-Distribution-of-Parameters)\n",
    "\n",
    "To get posterior samples of parameters, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params, acceptPrMH = posterior_sampler(Array(yields[18-p+1:end, 2:end]), Array(macros[18-p+1:end, 2:end]), tau_n, rho, iteration, tuned; medium_tau, std_kQ_infty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`yields[18-p+1:end, 2:end]` ensures that, regardless of how p is set, observations start from 1987 after the `p` initial observations. The same applies to `macros[18-p+1:end, 2:end]`.\n",
    "\n",
    "After the MCMC simulation, do the burn-in procedure. And then, erase posterior samples that do not satisfy the stationary condition. These works can be done by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params = saved_params[burnin+1:end]\n",
    "iteration = length(saved_params)\n",
    "\n",
    "saved_params, Pr_stationary = erase_nonstationary_param(saved_params)\n",
    "iteration = length(saved_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, `iteration` represents the number of remaining posterior samples. So, we have to adjust it when we discard some samples.\n",
    "\n",
    "Lastly, [calculate the inefficiency factors](https://econpreference.github.io/TermStructureModels.jl/dev/estimation/#Diagnostics-for-MCMC) by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineff = ineff_factor(saved_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Inferences\n",
    "\n",
    "To get [posterior samples of parameters](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Inference-for-Parameters) in the term structure model, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_params = reducedform(saved_params, Array(yields[18-p+1:end, 2:end]), Array(macros[18-p+1:end, 2:end]), tau_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yield curve interpolations](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Yield-Curve-Interpolation) can be done by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_latent_params = latentspace(saved_params, Array(yields[18-p+1:end, 2:end]), tau_n)\n",
    "fitted_yields = fitted_YieldCurve(collect(1:tau_n[end]), saved_latent_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first input of `fitted_YieldCurve` specifies the maturities for which we want to compute the fitted yields.\n",
    "\n",
    "Lastly, [the term premium](https://econpreference.github.io/TermStructureModels.jl/dev/inference/#Term-Premiums) is calculated by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_sub = (ineff[1] |> maximum, ineff[2], ineff[3] |> maximum, ineff[4] |> maximum, ineff[5] |> maximum, ineff[6] |> maximum) |> maximum |> ceil |> Int\n",
    "saved_TP = term_premium(TP_tau, tau_n, saved_params[1:iter_sub:end], Array(yields[18-p+1:end, 2:end]), Array(macros[18-p+1:end, 2:end]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iter_sub` is the ceiling of the maximum inefficiency factor, and `saved_params[1:iter_sub:end]` is the subsampling. Considering computational cost, we draw posterior samples of the term premium using only a subset of the posterior samples.\n",
    "\n",
    "There's no need to keep `saved_TP` in memory, so it's beneficial to store it on a storage device and free up memory space. This can be done with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD2.save(\"TP.jld2\", \"TP\", saved_TP)\n",
    "TP = nothing\n",
    "# GC.gc() # It's better to let the garbage collector work automatically, so we remove this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to this process as \"Garbage Collection\". `saved_TP` stored in \"TP.jld2\" can be loaded through\n",
    "\n",
    "```julia\n",
    "saved_TP = JLD2.load(\"TP.jld2\")[\"TP\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Forecasting](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Forecasting)\n",
    "\n",
    "### [Baseline Forecasts](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Baseline-Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = scenario_analysis([], scenario_TP, scenario_horizon, saved_params[1:iter_sub:end], Array(yields[18-p+1:end, 2:end]), Array(macros[18-p+1:end, 2:end]), tau_n; mean_macros)\n",
    "\n",
    "JLD2.save(\"uncond_scenario.jld2\", \"projections\", projections)\n",
    "projections = nothing\n",
    "# GC.gc() # It's better to let the garbage collector work automatically, so we remove this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also conduct the garbage collection. `projections` stored in \"uncond_scenario.jld2\" can be loaded through\n",
    "\n",
    "```julia\n",
    "projections = JLD2.load(\"uncond_scenario.jld2\")[\"projections\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Scenario Forecasts](https://econpreference.github.io/TermStructureModels.jl/dev/scenario/#Scenario-Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:2\n",
    "    projections = scenario_analysis(gen_scene(i), scenario_TP, scenario_horizon, saved_params[1:iter_sub:end], Array(yields[18-p+1:end, 2:end]), Array(macros[18-p+1:end, 2:end]), tau_n; mean_macros)\n",
    "    \n",
    "    JLD2.save(\"scenario$i.jld2\", \"projections\", projections)\n",
    "    projections = nothing\n",
    "    # GC.gc() # It's better to let the garbage collector work automatically, so we remove this line.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three lines are the garbage collection. You can load saved `projections` through `JLD2.load`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
